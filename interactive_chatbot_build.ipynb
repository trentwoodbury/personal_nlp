{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this notebook?\n",
    "This notebook takes in movie conversations and trains a chatbot to interact with people. This chatbot is trained via a tensorflow neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_in_lines():\n",
    "    with open('data/dialogues/movie_lines.txt', 'r') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "    with open('data/dialogues/movie_conversations.txt', 'r') as g:\n",
    "        conv_lines = g.read().split('\\n')\n",
    "    return lines, conv_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_line_mapping(lines):\n",
    "    '''\n",
    "    creates a dictionary mapping lineids to the lines.\n",
    "    '''\n",
    "    line_mapping = {}\n",
    "    for line in lines:\n",
    "        split_line = line.split(' +++$+++ ')\n",
    "        if len(split_line) == 5:\n",
    "            line_mapping[split_line[0]] = split_line[4]\n",
    "    return line_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_conv_lines(conv_lines):\n",
    "    '''\n",
    "    extracts just the line ids from the conv_lines list.\n",
    "    returns a list of lists of strings. Each string is a lineid.\n",
    "    '''\n",
    "    convs = []\n",
    "    for conv in conv_lines[:-1]:\n",
    "        conv_line_list = conv.split(\" +++$+++ \")[-1]\n",
    "        convs.append(ast.literal_eval(conv_line_list))\n",
    "    return convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_questions_and_answers(convs, line_mapping):\n",
    "    '''\n",
    "    creates a list of questions and a list of answers.\n",
    "    These are the back to back lines from each conversation.\n",
    "    '''\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for conv in convs:\n",
    "        for i in range(len(conv) - 1):\n",
    "            questions.append(line_mapping[conv[i]])\n",
    "            answers.append(line_mapping[conv[i+1]])\n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_clean_questions_and_answers(questions, answers):\n",
    "    '''\n",
    "    applies clean_text function to questions and answers lists.\n",
    "    '''\n",
    "    clean_questions = [clean_text(text) for text in questions]\n",
    "    clean_answers = [clean_text(text) for text in answers]\n",
    "    return clean_questions, clean_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_long_and_short_sentences(questions, answers, min_threshold=2, max_threshold=20):\n",
    "    '''\n",
    "    Filters out questions and answers with length below the min_threshold (2)\n",
    "    and above the max_threshold (20)\n",
    "    '''\n",
    "    questions_filtered = []\n",
    "    answers_filtered = []\n",
    "    \n",
    "    for q, a in zip(questions, answers):\n",
    "        if len(q.split()) > min_threshold and len(q.split()) < max_threshold and \\\n",
    "        len(a.split()) > min_threshold and len(a.split()) < max_threshold:\n",
    "            questions_filtered.append(q)\n",
    "            answers_filtered.append(a)\n",
    "   \n",
    "    return questions_filtered, answers_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_word_frequency_dictionaries(sentence_list):\n",
    "    '''\n",
    "    This function applies to either the list of questions of the list of answers.\n",
    "    It creates a dictionary mapping words to the number of times that word occurs.\n",
    "    '''\n",
    "    word_frequencies = {}\n",
    "    for sentence in sentence_list:\n",
    "        for word in sentence.split():\n",
    "            if word_frequencies.get(word, 0) == 0:\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    return word_frequencies    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_uncommon_words(vocab, threshold):\n",
    "    '''\n",
    "    filters out words from vocab dictionary (output of create_word_frequency_dictionaries)\n",
    "    that occurs fewer than threshold many times.\n",
    "    '''\n",
    "    filtered_vocab = {key: val for key, val in vocab.iteritems() if val >= threshold}\n",
    "    return filtered_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_unique_identifiers(vocab):\n",
    "    '''\n",
    "    creates dictionary mapping each word in vocab to a unique number\n",
    "    '''\n",
    "    words = set(vocab.keys())\n",
    "    vocab_identifiers = {}\n",
    "    unique_int = 0\n",
    "    for word in words:\n",
    "        vocab_identifiers[word] = unique_int\n",
    "        unique_int += 1\n",
    "    \n",
    "    return vocab_identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dictionary_tokens(vocab_identifiers):\n",
    "    '''\n",
    "    adds identification tokens to the vocab_identifiers dictionary\n",
    "    '''\n",
    "    codes = ['<PAD>','<EOS>','<UNK>','<GO>']\n",
    "\n",
    "    for code in codes:\n",
    "        vocab_identifiers[code] = len(filtered_vocab)+1\n",
    "    \n",
    "    # Rename vocab_identifiers now this has tokens. This is just for interpretability reasons.\n",
    "    identifiers_with_tokens = vocab_identifiers\n",
    "    return identifiers_with_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_int_to_word_dict(identifiers_with_tokens):\n",
    "    '''\n",
    "    creates a dictionary mapping integers to words as opposed to words mapping to \n",
    "    dictionaries.\n",
    "    '''\n",
    "    int_to_word_dict = {idx : word for word, idx in identifiers_with_tokens.iteritems()}\n",
    "    return int_to_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_eos_token(lines):\n",
    "    '''\n",
    "    Here lines is a list of strings (sentences). This will generally be either\n",
    "        questions_filtered (or)\n",
    "        answers_filtered\n",
    "    but any input of form list of strings will word.\n",
    "    This function appends ' <EOS>' to the end of each string, representing the\n",
    "    end of sentence.\n",
    "    '''\n",
    "    lines_with_eos = [x + ' <EOS>' for x in lines]\n",
    "    return lines_with_eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_lines_to_ints(lines, word_identifiers):\n",
    "    '''\n",
    "    converts list of lines to a list of list of integers where each integer represents\n",
    "    a word. The integer mapping is per the word_identifiers defined by the \n",
    "    create_unique_identifiers function. If a word isn't in the word_identifiers, it will be\n",
    "    replaces with '<UNK>' for unknown.\n",
    "    INPUT\n",
    "        lines: list of strings. Each string is a movie line.\n",
    "        word_identifiers: dictionary. maps words to unique identifiers. \n",
    "    OUTPUT\n",
    "        int_lines: list of list of integers.\n",
    "    '''\n",
    "    int_lines = []\n",
    "    for line in lines:\n",
    "        word_split = line.split()\n",
    "        words_as_ints = map(lambda x: word_identifiers.get(x, '<UNK>'), word_split)\n",
    "        int_lines.append(words_as_ints)\n",
    "    \n",
    "    return int_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Implementation \n",
    "(i.e. running the functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines, conv_lines = load_in_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_mapping = create_line_mapping(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convs = format_conv_lines(conv_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions, answers = create_questions_and_answers(convs, line_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_questions, clean_answers = create_clean_questions_and_answers(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions_filtered, answers_filtered = \\\n",
    "    filter_long_and_short_sentences(clean_questions, clean_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_freq = create_word_frequency_dictionaries(answers_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_vocab = filter_uncommon_words(vocab_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_identifiers = create_unique_identifiers(filtered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "identifiers_with_tokens = create_dictionary_tokens(word_identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_word_dict = create_int_to_word_dict(identifiers_with_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answers_filtered_eos = add_eos_token(answers_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_form_questions = convert_lines_to_ints(questions_filtered, word_identifiers)\n",
    "int_form_answers = convert_lines_to_ints(answers_filtered_eos, identifiers_with_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
