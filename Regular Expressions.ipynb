{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections_extended import setlist\n",
    "from itertools import permutations\n",
    "import nltk\n",
    "from nltk import *\n",
    "import re, pprint\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions (Regex)\n",
    "Regular expressions are ways of formatting strings to specify a certain search pattern. If you are looking for patterns in text, regular expressions are what you can use.<br><br>\n",
    "\n",
    "Instead of going through the philosophy of regular expressions, this tutorial will outline different pieces of regex and show examples of those pieces in action. Let's dive in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "<b>^</b> denotes the beginning of a word. <br>\n",
    "<b>.</b> is a wildcard character <br>\n",
    "<b>$</b> denotes the end of a word.<br>\n",
    "<b>?</b> means that the previous character is optional. <br>\n",
    "<b>[abc]</b> means that the character in this space can be any of a, b, or c. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'abjectly', u'adjuster', u'dejected', u'dejectly', u'injector', u'majestic', u'objectee', u'objector', u'rejecter', u'rejector']\n"
     ]
    }
   ],
   "source": [
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "# print words with j and t in the middle of length 8\n",
    "print [w for w in wordlist if re.search('^..j..t..$', w)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'intervention', u'invention']\n"
     ]
    }
   ],
   "source": [
    "print [w for w in wordlist if re.search('^int?e?r?vention$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'adglutinate', u'afikomen', u'beglad', u'beglamour', u'beglare', u'beglerbeg', u'beglerbeglic', u'beglerbegluc', u'beglerbegship', u'beglerbey']\n"
     ]
    }
   ],
   "source": [
    "print [w for w in wordlist if re.search('^[abc][def][ghi][jkl]', w)][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>+</b> means 1 or more instances of the item<br>\n",
    "<b>\\*</b> means 0 or more instances of an item<br>\n",
    "+, * are refered to as <b>closures</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'po', u'poaceous', u'poach', u'poachable', u'poacher', u'poachiness', u'poachy', u'poalike', u'pob', u'pobby']\n"
     ]
    }
   ],
   "source": [
    "print [w for w in wordlist if re.search('^p+o+p*', w)][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>^</b> inside a bracket matches to any character not inside the bracket.<br>\n",
    "In the example below, we see words with no vowels in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'b', u'by', u'byth', u'c', u'cly', u'cry', u'crypt', u'cwm', u'cyp', u'cyst']\n"
     ]
    }
   ],
   "source": [
    "print [w for w in wordlist if re.search('^[^aeiouAEIOU]+$', w)][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>|</b> is refered to as the disjunction. It is an OR operator. <br>\n",
    "<b>{n}</b> specifies exactly n repeats. <br>\n",
    "<b>{n,}</b> specifies at least n repeats. <br>\n",
    "<b>{,n}</b> specifies at most n repeats.<br>\n",
    "<b>{n,m}</b> specifies between n and m repeats <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'blype', u'bryaceous', u'bryogenin', u'bryological', u'bryologist', u'bryology', u'bryonidin', u'bryonin', u'bryony', u'bryophyte']\n"
     ]
    }
   ],
   "source": [
    "# words with at least 3 non-vowels at the beginning\n",
    "print [w for w in wordlist if re.search('^[^aeiouAEIOU]{3,}', w)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'a', u'aa', u'aal', u'aalii', u'aam', u'aardvark', u'aardwolf', u'aba', u'abac', u'abaca']\n"
     ]
    }
   ],
   "source": [
    "# words with no more than 3 consonants at the beginning\n",
    "print [w for w in wordlist if re.search('^[^aeiouAEIOU]{,3}', w)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'blype', u'byplay', u'byrlaw', u'byrlawman', u'byrnie', u'byrrus', u'byrthynsak', u'bysmalith', u'byspell', u'byssaceous']\n"
     ]
    }
   ],
   "source": [
    "# words with between 4 and 6 consonants at the beginning\n",
    "print [w for w in wordlist if re.search('^[^aeiouAEIOU]{4,6}', w)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'accosted', u'arresting', u'ballasting', u'basting', u'beforested', u'billposting', u'bilsted', u'blasted', u'blasting', u'bloodthirsting']\n"
     ]
    }
   ],
   "source": [
    "# words that end with 'sting' or 'sted'\n",
    "# () tell us the scope of the operator\n",
    "print [w for w in wordlist if re.search('(sting|sted)$', w)][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Regular Expressions for Texts\n",
    "So far we have only been using regular expressins for single words. We can also use regular expressions across words in a text, though. Here we can interact with an NLTK Text object to find instances of a regular expression. <br><br>\n",
    "\n",
    "When you want to look for a pattern of words, we delineate different words using <b>&lt;word&gt; &lt;word&gt; &lt;word&gt;</b>\n",
    "<br><br>\n",
    "\n",
    "Because NLTK's built in findall function prints results instead of returning them (why?), I have defined my own function that returns the results instead.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_regex_token_match(regexp, nltk_text):\n",
    "    '''\n",
    "    NLTK's finall method prints the results instead of returning them.\n",
    "    Since this is worthless for any real world application, I have \n",
    "    tweaked their source code to return instead of print the results\n",
    "    by using this function instead of nltk.find_all.\n",
    "    INPUT\n",
    "        nltk_text: an NLTK text object\n",
    "        regexp: a resular expression\n",
    "    OUTPUT\n",
    "        match_list: a list of tokens\n",
    "    '''\n",
    "    if \"_token_searcher\" not in nltk_text.__dict__:\n",
    "            nltk_text._token_searcher = nltk.TokenSearcher(nltk_text)\n",
    "    hits = nltk_text._token_searcher.findall(regexp)\n",
    "    return [' '.join(h) for h in hits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at words used to describe men and women in Moby Dick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men Descriptions: {[u'artificial', u'any', u'that', u'a', u'monied', u'nervous', u'old', u'decent', u'This', u'this', u'No', u'the', u'dangerous', u'white', u'one', u'That', u'every', u'worsted', u'faithful', u'Miserable', u'honest', u'is', u'fellow', u'no', u'first', u'elderly', u'!', u'young', u'Young', u'pious', u'our', u'impenitent', u',', u'queer', u'like', u'good', u'crazy', u'of', u'mature', u'earnest', u'steadfast', u'fearless', u'mighty', u'but', u'ruined', u'-', u'unfearing', u'Cape', u'sepulchral', u'other', u'sleeping', u'less', u'little', u'great', u'wise', u'better', u'by', u'are', u'from', u'handed', u'and', u'butterless', u'meditative', u'If', u'mortal', u'to', u'very', u'fiendish', u'for', u'Albino', u'pale', u'spiritual', u'manufactured', u'Every', u'dead', u'last', u'legs', u'maimed', u'best', u'each', u'monomaniac', u'Any', u'infatuated', u'your', u'their', u'Teneriffe', u'furious', u'half', u'experienced', u'baby', u'killed', u'brack', u'single', u'O', u'timid', u'youngish', u'certain', u'drowned', u'same', u'than', u'in', u'stoutest', u'In', u'with', u'common', u'looking', u'though', u'yet', u'So', u'cases', u'ornamented', u'legged', u'abstinence', u'learned', u'per', u'untravelled', u'abstracted', u'complete', u'dismasted', u'younger', u'sick', u'civilized', u'cast', u'Old', u'brave', u'upright', u'suffering', u'only', u'nor', u'between', u'third'}] \n",
      "\n",
      "Women Descriptions: {[u'old', u'freckled', u'any', u'mortal', u'a'}]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg, nps_chat\n",
    "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))\n",
    "\n",
    "\n",
    "man_descriptions = create_regex_token_match(r\"(<.*>)<man>\", moby)\n",
    "woman_descriptions = create_regex_token_match(r\"(<.*>)<woman>\", moby)\n",
    "print \"Men Descriptions:\", setlist(man_descriptions), \"\\n\"\n",
    "print \"Women Descriptions:\", setlist(woman_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at plural words related by \"and\" within the brown text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'lats', u'serratus'), (u'judges', u'audiences'), (u'rhythms', u'infectious'), (u'swoops', u'slides'), (u'parents', u'guests'), (u'hands', u'legs'), (u'us', u'has'), (u'lakes', u'reservoirs'), (u'Designers', u'manufacturers'), (u'Terms', u'rates')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "hobbies_learned = nltk.Text(brown.words(categories=['hobbies', 'learned']))\n",
    "related_hobbies = create_regex_token_match(r\"<\\w*s> <and> <\\w*s>\", hobbies_learned)\n",
    "print [(val.split(\" \")[0], val.split(\" \")[-1]) for val in related_hobbies[:10]]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
